{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision.transforms import ToTensor, ToPILImage\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from PIL import Image\n",
    "from pathlib import Path\n",
    "import plotly.express as px\n",
    "import math\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = Path(\"E:/user/Notebooks/data/plant-pathology-2020-fgvc7/images/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = Image.open(PATH/\"Train_1815.jpg\")\n",
    "px.imshow(img);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train_df_names = pd.read_csv(\"train.csv\")[\"image_id\"].values\n",
    "#test_df_names = pd.read_csv(\"test.csv\")[\"image_id\"].values\n",
    "#len(train_df_names), len(test_df_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train_imgs = [np.array(Image.open(PATH/(i+\".jpg\"))) for i in train_df_names[:1]]\n",
    "#len(train_imgs) ,train_imgs[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_image(pth): #Hocanın yazdığı\n",
    "    img = Image.open(pth)\n",
    "    return ((ToTensor()(img.resize((256,256)))).type(torch.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dataset:\n",
    "    def __init__(self, df, path):\n",
    "        self.df = df\n",
    "        self.path = path\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "    \n",
    "    def __getitem__(self, idxs):\n",
    "        if isinstance(idxs, int):\n",
    "            imgs = transform_image(self.path/(self.df[\"image_id\"][idxs]+\".jpg\"))\n",
    "            labels = torch.tensor(self.df.iloc[:,1:].iloc[idxs].values, dtype=torch.float32)\n",
    "            ids = self.df.iloc[:,0].iloc[idxs]\n",
    "            \n",
    "            return imgs.cuda(), labels.cuda()\n",
    "        else:\n",
    "            sub_df = self.df.iloc[idxs]\n",
    "            imgs = []\n",
    "            labels = []\n",
    "            ids = []\n",
    "            for i in range(len(idxs)):\n",
    "                img = transform_image(self.path/(sub_df[\"image_id\"].iloc[i]+\".jpg\"))\n",
    "                image_id = sub_df[\"image_id\"].iloc[i]\n",
    "                ids.append(image_id)\n",
    "                imgs.append(img)\n",
    "                label = torch.tensor(sub_df.iloc[:,1:].iloc[i].values, dtype=torch.float32)\n",
    "                labels.append(label)\n",
    "                \n",
    "            return torch.stack(imgs,dim=0).cuda(), torch.stack(labels,dim=0).cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataLoader():\n",
    "    def __init__(self, ds, bs): \n",
    "        self.ds, self.bs = ds, bs\n",
    "    def __iter__(self):\n",
    "        n = len(self.ds)\n",
    "        l = torch.randperm(n)\n",
    "\n",
    "        for i in range(0, n, self.bs): \n",
    "            idxs_l = l[i:i+self.bs]\n",
    "            yield self.ds[idxs_l]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_last = pd.read_csv(\"E:/user/Notebooks/data/plant-pathology-2020-fgvc7/train_last_df.csv\")\n",
    "train_aug = pd.read_csv(\"E:/user/Notebooks/data/plant-pathology-2020-fgvc7/train_aug_df.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "healthy 413\n",
      "multiple_diseases 528\n",
      "rust 498\n",
      "scab 474\n"
     ]
    }
   ],
   "source": [
    "print('healthy',len(train_last[train_last['healthy']==1]))\n",
    "print('multiple_diseases',len(train_last[train_last['multiple_diseases']==1]))\n",
    "print('rust',len(train_last[train_last['rust']==1]))\n",
    "print('scab',len(train_last[train_last['scab']==1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df=pd.DataFrame(columns=['image_id','healthy','multiple_diseases','rust','scab'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "frames = [train_last, train_aug]\n",
    "train_df = pd.concat(frames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_id</th>\n",
       "      <th>healthy</th>\n",
       "      <th>multiple_diseases</th>\n",
       "      <th>rust</th>\n",
       "      <th>scab</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Train_886_3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Train_1794</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Train_592</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Train_980</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Train_631</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5734</th>\n",
       "      <td>Train_1129_1_0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5735</th>\n",
       "      <td>Train_1554_1_2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5736</th>\n",
       "      <td>Train_812_1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5737</th>\n",
       "      <td>Train_1113_1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5738</th>\n",
       "      <td>Train_1433_3_0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7652 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            image_id  healthy  multiple_diseases  rust  scab\n",
       "0        Train_886_3        0                  1     0     0\n",
       "1         Train_1794        1                  0     0     0\n",
       "2          Train_592        1                  0     0     0\n",
       "3          Train_980        1                  0     0     0\n",
       "4          Train_631        0                  0     0     1\n",
       "...              ...      ...                ...   ...   ...\n",
       "5734  Train_1129_1_0        0                  1     0     0\n",
       "5735  Train_1554_1_2        0                  1     0     0\n",
       "5736     Train_812_1        1                  0     0     0\n",
       "5737    Train_1113_1        0                  0     1     0\n",
       "5738  Train_1433_3_0        0                  1     0     0\n",
       "\n",
       "[7652 rows x 5 columns]"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((7652, 5), (363, 5))"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valid_df = pd.read_csv(\"E:/user/Notebooks/data/plant-pathology-2020-fgvc7/valid_last_df.csv\")\n",
    "train_df.shape, valid_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_PATH = Path('E:/user/Notebooks/data/plant-pathology-2020-fgvc7/train_karisik')\n",
    "VALID_PATH = Path('E:/user/Notebooks/data/plant-pathology-2020-fgvc7/valid_last')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = Dataset(train_df,TRAIN_PATH)\n",
    "train_dl = DataLoader(train_ds, 128)\n",
    "\n",
    "valid_ds = Dataset(valid_df, VALID_PATH)\n",
    "valid_dl = DataLoader(valid_ds, 128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([128, 3, 256, 256]), torch.Size([128, 4]))"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x1,y1= next(iter(valid_dl))\n",
    "x1.shape, y1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(predictions, target):\n",
    "    predictions = predictions.view(-1,4)\n",
    "    target = target.view(-1,4)\n",
    "    preds = [torch.argmax(i).item() for i in predictions]\n",
    "    targs = [torch.argmax(i).item() for i in target]\n",
    "    return np.mean([preds[i]==targs[i] for i in range(len(preds))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validation_acc(model, valid_dl):\n",
    "    return torch.tensor([accuracy(model(xb), yb) for xb, yb in valid_dl]).mean().item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([128, 3, 256, 256]), torch.Size([128, 4]))"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x1,y1= next(iter(valid_dl))\n",
    "x1.shape, y1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = nn.Sequential(\n",
    "        nn.Conv2d(3,8,5,padding=2,stride=2),nn.ReLU(), nn.BatchNorm2d(8), nn.Dropout2d(0.05),\n",
    "        nn.Conv2d(8,16,5,padding=1,stride=2), nn.ReLU(), nn.BatchNorm2d(16), nn.Dropout2d(0.1),\n",
    "        nn.Conv2d(16,32,5,padding=1,stride=2), nn.ReLU(), nn.BatchNorm2d(32), nn.Dropout2d(0.2),\n",
    "        nn.Flatten(),\n",
    "        nn.Linear(32*31*31,64), nn.ReLU(), nn.Dropout(0.4),\n",
    "        nn.Linear(64,4)\n",
    ").cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2643107476635514"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validation_acc(model, valid_dl)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Experiment parameters\n",
    "lr_find_epochs = 2\n",
    "start_lr = 1e-7\n",
    "end_lr = 0.1\n",
    "lr_lambda = lambda x: math.exp(x * math.log(end_lr / start_lr) / (lr_find_epochs* 128))\n",
    "#scheduler = torch.optim.lr_scheduler.LambdaLR(optim, lr_lambda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "optim = torch.optim.Adam(model.parameters(), lr=0.002)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#from torch_lr_finder import LRFinder\n",
    "lr_finder = LRFinder(model, optim, criterion, device=\"cuda\")\n",
    "lr_finder.range_test(train_dl, end_lr=100, num_iter=100)\n",
    "lr_finder.plot() # to inspect the loss-learning rate graph\n",
    "lr_finder.reset() # to reset the model and optimizer to their initial state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.BCEWithLogitsLoss() # Ne işe yarıyor?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, loss_criterion, optimizer, data_loader, valid_data_loader, epochs, valid_epoch):\n",
    "    model = model.train()\n",
    "    \n",
    "    for epoch in range(1,epochs+1):\n",
    "        model = model.train()\n",
    "        general_loss = 0\n",
    "        \n",
    "        for xb, yb in data_loader: #xb image, yb label döndürüyor. İkisi de tensor\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            predictions = model(xb)\n",
    "#             y = predictions.detach().cpu().numpy()\n",
    "#             np.savetxt(\"output.csv\",y)\n",
    "            \n",
    "            loss = loss_criterion(predictions, yb)\n",
    "            loss.backward()\n",
    "            \n",
    "            optimizer.step()\n",
    "            \n",
    "            general_loss += loss.item()\n",
    "\n",
    "        if epoch % valid_epoch == 0:\n",
    "            model = model.eval()\n",
    "            with torch.no_grad():\n",
    "                print(\"Epoch: [%d] | Loss: %.3f | Train Accuracy: %.2f | Validation Accuracy: %.2f\"  % (epoch, general_loss, accuracy(predictions,yb), validation_acc(model,valid_dl))) # accuracy fonksiyonu yaz."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [1] | Loss: 37.610 | Train Accuracy: 0.33 | Validation Accuracy: 0.33\n",
      "Epoch: [2] | Loss: 33.994 | Train Accuracy: 0.39 | Validation Accuracy: 0.36\n",
      "Epoch: [3] | Loss: 32.086 | Train Accuracy: 0.48 | Validation Accuracy: 0.34\n",
      "Epoch: [4] | Loss: 29.672 | Train Accuracy: 0.41 | Validation Accuracy: 0.33\n",
      "Epoch: [5] | Loss: 25.771 | Train Accuracy: 0.62 | Validation Accuracy: 0.35\n",
      "Epoch: [6] | Loss: 21.484 | Train Accuracy: 0.62 | Validation Accuracy: 0.42\n",
      "Epoch: [7] | Loss: 18.626 | Train Accuracy: 0.65 | Validation Accuracy: 0.42\n",
      "Epoch: [8] | Loss: 15.501 | Train Accuracy: 0.72 | Validation Accuracy: 0.48\n",
      "Epoch: [9] | Loss: 13.758 | Train Accuracy: 0.80 | Validation Accuracy: 0.38\n",
      "Epoch: [10] | Loss: 12.011 | Train Accuracy: 0.85 | Validation Accuracy: 0.53\n",
      "Epoch: [11] | Loss: 11.221 | Train Accuracy: 0.86 | Validation Accuracy: 0.51\n",
      "Epoch: [12] | Loss: 9.416 | Train Accuracy: 0.91 | Validation Accuracy: 0.52\n",
      "Epoch: [13] | Loss: 8.854 | Train Accuracy: 0.87 | Validation Accuracy: 0.56\n",
      "Epoch: [14] | Loss: 8.535 | Train Accuracy: 0.77 | Validation Accuracy: 0.53\n",
      "Epoch: [15] | Loss: 8.288 | Train Accuracy: 0.87 | Validation Accuracy: 0.59\n",
      "Epoch: [16] | Loss: 7.497 | Train Accuracy: 0.84 | Validation Accuracy: 0.61\n",
      "Epoch: [17] | Loss: 7.455 | Train Accuracy: 0.92 | Validation Accuracy: 0.58\n",
      "Epoch: [18] | Loss: 7.119 | Train Accuracy: 0.84 | Validation Accuracy: 0.59\n",
      "Epoch: [19] | Loss: 6.545 | Train Accuracy: 0.89 | Validation Accuracy: 0.54\n",
      "Epoch: [20] | Loss: 6.279 | Train Accuracy: 0.92 | Validation Accuracy: 0.54\n"
     ]
    }
   ],
   "source": [
    "train_model(model, criterion, optim, train_dl, valid_dl, 20, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: h5py in e:\\user\\anaconda\\lib\\site-packages (2.10.0)\n",
      "Requirement already satisfied: numpy>=1.7 in e:\\user\\anaconda\\lib\\site-packages (from h5py) (1.18.5)\n",
      "Requirement already satisfied: six in c:\\users\\user\\appdata\\roaming\\python\\python38\\site-packages (from h5py) (1.14.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install h5py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "torch.save(model.state_dict(),'E:/user/Notebooks/data/plant-pathology-2020-fgvc7/base_model.h5')\n",
    "#model.save(\"E:/user/Notebooks/data/plant-pathology-2020-fgvc7/base_model.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
